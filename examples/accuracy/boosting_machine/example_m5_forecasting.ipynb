{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2021 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Machine on M5 Forecasting Accuracy Dataset\n",
    "\n",
    "## Background \n",
    "\n",
    "The goal of this learning task is to predict the daily sales in Walmart, the world's largest company by revenue, based on hierachical sales data from the past two years.\n",
    "\n",
    "## Source\n",
    "\n",
    "The raw dataset can be obtained directly from [Kaggle](https://www.kaggle.com/competitions/m5-forecasting-accuracy). \n",
    "\n",
    "In this example, we download the dataset directly from Kaggle using their API. \n",
    "\n",
    "In order for this to work, you must login into Kaggle and folow [these instructions](https://www.kaggle.com/docs/api) to install your API token on your machine.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to illustrate how Snap ML's boosting machine can perform Poisson regression and provide best-in-class accuracy when compared to XGBoost and LightGBM.\n",
    "\n",
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/test/Work/IBM/GradientBoosting/loss/snapml-1.12.0/snapml-examples/examples\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.637476Z",
     "iopub.status.busy": "2021-03-01T18:41:47.636547Z",
     "iopub.status.idle": "2021-03-01T18:41:47.638989Z",
     "shell.execute_reply": "2021-03-01T18:41:47.639682Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE_DIR='cache-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.644878Z",
     "iopub.status.busy": "2021-03-01T18:41:47.644123Z",
     "iopub.status.idle": "2021-03-01T18:41:50.150756Z",
     "shell.execute_reply": "2021-03-01T18:41:50.151221Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasets import M5Forecasting\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from snapml import BoostingMachineRegressor as SnapBoostingMachineRegressor\n",
    "from sklearn.metrics import mean_poisson_deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:50.155800Z",
     "iopub.status.busy": "2021-03-01T18:41:50.155146Z",
     "iopub.status.idle": "2021-03-01T18:41:50.499188Z",
     "shell.execute_reply": "2021-03-01T18:41:50.499565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating working directory: cache-dir/M5Forecasting\n",
      "Downloading M5Forecasting dataset.\n",
      "Please note: subsequent calls to `get_train_test_split` will read cached binary data, and thus be much faster.\n",
      "Downloading m5-forecasting-accuracy.zip to /home/test/Work/IBM/GradientBoosting/loss/snapml-1.12.0/snapml-examples/examples/cache-dir/M5Forecasting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45.8M/45.8M [00:03<00:00, 14.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing M5Forecasting dataset.\n",
      "Writing binary M5Forecasting dataset (cache) to disk.\n"
     ]
    }
   ],
   "source": [
    "dataset = M5Forecasting(cache_dir=CACHE_DIR)\n",
    "X_train, X_test, y_train, y_test = dataset.get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:50.503412Z",
     "iopub.status.busy": "2021-03-01T18:41:50.502860Z",
     "iopub.status.idle": "2021-03-01T18:41:50.632471Z",
     "shell.execute_reply": "2021-03-01T18:41:50.632804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 10237085\n",
      "Number of features: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: %d\" % (X_train.shape[0]))\n",
    "print(\"Number of features: %d\" % (X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train all 3 boosting frameworks the Poisson objective. \n",
    "\n",
    "We will use the following parameters for the optimization in all cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUND = 100\n",
    "LEARNING_RATE = 0.5\n",
    "MAX_DEPTH = 6\n",
    "NUM_THREADS = 8\n",
    "LAMBDA_2 = 0.1\n",
    "MAX_DELTA_STEP = 0.7\n",
    "MAX_BINS = 256\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['poisson_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Prediction:\n",
      "         poisson_loss\n",
      "xgboost      1.475857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/986704095.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(res_xgboost)\n"
     ]
    }
   ],
   "source": [
    "params_xgb = dict(    \n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_estimators=NUM_ROUND,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    reg_lambda = LAMBDA_2,\n",
    "    max_delta_step = MAX_DELTA_STEP,\n",
    "    n_jobs = NUM_THREADS,    \n",
    "    min_child_weight = 0.0,  \n",
    "    max_bin = MAX_BINS,\n",
    "    random_state=RANDOM_STATE, \n",
    ")\n",
    "\n",
    "gbr_x = XGBRegressor(objective=\"count:poisson\",                    \n",
    "                   tree_method='hist',\n",
    "                   **params_xgb)\n",
    "                        \n",
    "gbr_x.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost Prediction   \n",
    "score_xgboost = mean_poisson_deviance(y_test, gbr_x.predict(X_test))\n",
    "    \n",
    "res_xgboost = pd.Series({'poisson_loss': score_xgboost}, name='xgboost')\n",
    "df = df.append(res_xgboost)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          poisson_loss\n",
      "xgboost       1.475857\n",
      "lightgbm      1.493048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/3463310010.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(res_lightgbm)\n"
     ]
    }
   ],
   "source": [
    "params_lgb = dict(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_estimators=NUM_ROUND,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    reg_alpha = LAMBDA_2,\n",
    "    max_delta_step = MAX_DELTA_STEP,\n",
    "    n_jobs = NUM_THREADS, \n",
    "    min_child_weight = 0.0,\n",
    "    max_bin = MAX_BINS,\n",
    "    random_state=RANDOM_STATE,     \n",
    "    num_leaves = 2^MAX_DEPTH +1,\n",
    ")\n",
    "\n",
    "gbr_l = LGBMRegressor(objective='poisson',\n",
    "                      **params_lgb)\n",
    "                        \n",
    "gbr_l.fit(X_train, y_train)\n",
    "\n",
    "# LightGBM Prediction\n",
    "score_lightgbm = mean_poisson_deviance(y_test, gbr_l.predict(X_test))\n",
    "\n",
    "res_lightgbm = pd.Series({'poisson_loss': score_lightgbm}, name='lightgbm')\n",
    "df = df.append(res_lightgbm)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SnapBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          poisson_loss\n",
      "xgboost       1.475857\n",
      "lightgbm      1.493048\n",
      "snapml        1.474347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4265/1652979351.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(res_snapml)\n"
     ]
    }
   ],
   "source": [
    "params_snap = dict(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_round=NUM_ROUND,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    lambda_l2 = LAMBDA_2,\n",
    "    max_delta_step = MAX_DELTA_STEP,\n",
    "    n_jobs = NUM_THREADS,\n",
    "    use_gpu =  False,\n",
    "    use_histograms = True,\n",
    "    hist_nbins = MAX_BINS\n",
    ")\n",
    "\n",
    "\n",
    "gbr_s = SnapBoostingMachineRegressor(objective = \"poisson\",\n",
    "                                    random_state=42, \n",
    "                                    **params_snap)\n",
    "                             \n",
    "gbr_s.fit(X_train, y_train)\n",
    "\n",
    "# SnapBoost Prediction    \n",
    "score_snapml = mean_poisson_deviance(y_test, gbr_s.predict(X_test))\n",
    "\n",
    "res_snapml = pd.Series({'poisson_loss': score_snapml}, name='snapml')\n",
    "df = df.append(res_snapml)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poisson_loss</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>snapml</th>\n",
       "      <td>1.474347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>1.475857</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>1.493048</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          poisson_loss  rank\n",
       "snapml        1.474347   1.0\n",
       "xgboost       1.475857   2.0\n",
       "lightgbm      1.493048   3.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='poisson_loss')\n",
    "df['rank'] = df['poisson_loss'].rank()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Performance results always depend on the hardware and software environment. \n",
    "\n",
    "Information regarding the environment that was used to run this notebook are provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            platform: Linux-5.4.0-144-generic-x86_64-with-glibc2.31\n",
      "           cpu_count: 28\n",
      "        cpu_freq_min: 1200.0\n",
      "        cpu_freq_max: 3100.0\n",
      "        total_memory: 125.48433685302734\n",
      "      snapml_version: 1.12.0\n",
      "     sklearn_version: 1.2.1\n",
      "     xgboost_version: 1.7.4\n",
      "    lightgbm_version: 3.1.1\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "environment = utils.get_environment()\n",
    "for k,v in environment.items():\n",
    "    print(\"%20s: %s\" % (k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Statistics\n",
    "\n",
    "Finally, we record the enviroment and performance statistics for analysis outside of this standalone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "cpu_count": 28,
        "cpu_freq_max": 3100,
        "cpu_freq_min": 1200,
        "dataset": "M5Forecasting",
        "lightgbm_version": "3.1.1",
        "model": "BoostingMachineRegressor",
        "n_examples_test": 884210,
        "n_examples_train": 10237085,
        "n_features": 13,
        "platform": "Linux-5.4.0-144-generic-x86_64-with-glibc2.31",
        "score": "mean_poisson_deviance",
        "score_lightgbm": 1.4930475765992408,
        "score_snapml": 1.4743469508583271,
        "score_xgboost": 1.4758570288961828,
        "sklearn_version": "1.2.1",
        "snapml_version": "1.12.0",
        "total_memory": 125.48433685302734,
        "xgboost_version": "1.7.4"
       },
       "encoder": "json",
       "name": "result",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scrapbook as sb\n",
    "sb.glue(\"result\", {\n",
    "    'dataset': dataset.name,\n",
    "    'n_examples_train': X_train.shape[0],\n",
    "    'n_examples_test': X_test.shape[0],\n",
    "    'n_features': X_train.shape[1],\n",
    "    'model': 'BoostingMachineRegressor',\n",
    "    'score': 'mean_poisson_deviance',    \n",
    "    'score_xgboost': score_xgboost,\n",
    "    'score_lightgbm': score_lightgbm,\n",
    "    'score_snapml': score_snapml,\n",
    "    **environment,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
