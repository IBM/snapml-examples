{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2021 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Machine on Credit Card Fraud Dataset\n",
    "\n",
    "## Background \n",
    "\n",
    "The goal of this learning task is to predict if a credit card transaction is fraudulent or genuine based on a set of anonymized features.\n",
    "\n",
    "## Source\n",
    "\n",
    "The raw dataset can be obtained directly from [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud). \n",
    "\n",
    "In this example, we download the dataset directly from Kaggle using their API. \n",
    "\n",
    "In order for this to work, you must login into Kaggle and folow [these instructions](https://www.kaggle.com/docs/api) to install your API token on your machine.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to illustrate how Snap ML's boosting machine can provide best-in-class accuracy when compared to XGBoost and LightGBM.\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.624289Z",
     "iopub.status.busy": "2021-03-01T18:41:47.623074Z",
     "iopub.status.idle": "2021-03-01T18:41:47.630882Z",
     "shell.execute_reply": "2021-03-01T18:41:47.631866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tpa/Code/snapml-examples/examples\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.637476Z",
     "iopub.status.busy": "2021-03-01T18:41:47.636547Z",
     "iopub.status.idle": "2021-03-01T18:41:47.638989Z",
     "shell.execute_reply": "2021-03-01T18:41:47.639682Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE_DIR='cache-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.644878Z",
     "iopub.status.busy": "2021-03-01T18:41:47.644123Z",
     "iopub.status.idle": "2021-03-01T18:41:50.150756Z",
     "shell.execute_reply": "2021-03-01T18:41:50.151221Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasets import CreditCardFraud\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from snapml import BoostingMachineClassifier as SnapBoostingMachineClassifier\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, train_test_split, PredefinedSplit\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:50.155800Z",
     "iopub.status.busy": "2021-03-01T18:41:50.155146Z",
     "iopub.status.idle": "2021-03-01T18:41:50.499188Z",
     "shell.execute_reply": "2021-03-01T18:41:50.499565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading binary CreditCardFraud dataset (cache) from disk.\n"
     ]
    }
   ],
   "source": [
    "dataset = CreditCardFraud(cache_dir=CACHE_DIR)\n",
    "X_train, X_test, y_train, y_test = dataset.get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:50.503412Z",
     "iopub.status.busy": "2021-03-01T18:41:50.502860Z",
     "iopub.status.idle": "2021-03-01T18:41:50.632471Z",
     "shell.execute_reply": "2021-03-01T18:41:50.632804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 213605\n",
      "Number of features: 28\n",
      "Number of classes:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: %d\" % (X_train.shape[0]))\n",
    "print(\"Number of features: %d\" % (X_train.shape[1]))\n",
    "print(\"Number of classes:  %d\" % (len(np.unique(y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind, val_ind = train_test_split(range(0, X_train.shape[0]), test_size=0.3, \n",
    "                                      shuffle=True, random_state=42)\n",
    "tmp = np.zeros(shape=(X_train.shape[0],))\n",
    "for i in train_ind:\n",
    "    tmp[i] = -1\n",
    "splitter = PredefinedSplit(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the class weights (to account for imbalance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5008652385150725, 1: 289.43766937669375}\n"
     ]
    }
   ],
   "source": [
    "class_weights = {\n",
    "    0: y_train.shape[0]/2.0/np.sum(y_train == 0),\n",
    "    1: y_train.shape[0]/2.0/np.sum(y_train == 1)\n",
    "}\n",
    "print(class_weights)\n",
    "\n",
    "w_train = compute_sample_weight(class_weights, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom scoring function (class-weighted logistic loss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_log_loss(y, p):\n",
    "    w = compute_sample_weight(class_weights, y)\n",
    "    return log_loss(y, p.astype(np.float64), sample_weight=w)\n",
    "\n",
    "scorer = make_scorer(weighted_log_loss, greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tune all 3 boosting frameworks using the `HalvingRandomSearchCV` optimizer from scikit-learn. \n",
    "\n",
    "We will use the following parameters for the optimization in all cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_params = {\n",
    "    'n_candidates': 256,\n",
    "    'min_resources': 16,\n",
    "    'max_resources': 1024,\n",
    "    'factor': 4,\n",
    "    'scoring': scorer,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': 4,\n",
    "    'cv': splitter,\n",
    "    'return_train_score': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['t_fit', 'holdout_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost hyper-parameters:\n",
      "                     subsample: 0.6326530612244898\n",
      "                    reg_lambda: 56.89866029018293\n",
      "                     max_depth: 1\n",
      "                 learning_rate: 0.09319395762340775\n",
      "              colsample_bytree: 0.7142857142857143\n",
      "                  n_estimators: 1024\n",
      "              t_fit  holdout_score\n",
      "xgboost  269.207851        0.26633\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(random_state=42, \n",
    "                    n_jobs=1,\n",
    "                    max_bin=256,\n",
    "                    tree_method='hist',\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='logloss')\n",
    "\n",
    "xgb_distributions = {\n",
    "    \"max_depth\": range(1, 20),\n",
    "    \"learning_rate\": 10 ** np.linspace(-2.5, -1),\n",
    "    \"colsample_bytree\": np.linspace(0.5, 1.0),\n",
    "    \"subsample\": np.linspace(0.5, 1.0),\n",
    "    \"reg_lambda\": 10 ** np.linspace(-2, 2)\n",
    "}\n",
    "\n",
    "search = HalvingRandomSearchCV(clf, xgb_distributions, resource='n_estimators', **sh_params)\n",
    "                        \n",
    "t0 = time.time()\n",
    "with parallel_backend(\"loky\"): \n",
    "    search.fit(X_train, y_train.astype(np.int32), sample_weight=w_train)\n",
    "t_fit_xgboost  = time.time()-t0\n",
    "\n",
    "print(\"Optimized XGBoost hyper-parameters:\")\n",
    "for k, v in search.best_params_.items():\n",
    "    print(\"%30s:\" % (k), v)\n",
    "    \n",
    "score_xgboost = weighted_log_loss(y_test, search.predict_proba(X_test)[:,1])\n",
    "\n",
    "res_xgboost = pd.Series({'t_fit': t_fit_xgboost, 'holdout_score': score_xgboost}, name='xgboost')\n",
    "df = df.append(res_xgboost)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpa/anaconda3/envs/snapenv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized LightGBM hyper-parameters:\n",
      "                     subsample: 0.9387755102040816\n",
      "                    reg_lambda: 0.04498432668969444\n",
      "                    num_leaves: 4\n",
      "                 learning_rate: 0.05302611335911987\n",
      "              colsample_bytree: 0.7857142857142857\n",
      "                  n_estimators: 1024\n",
      "               t_fit  holdout_score\n",
      "xgboost   269.207851       0.266330\n",
      "lightgbm  213.848340       0.381463\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier(random_state=42, \n",
    "                     n_jobs=1, \n",
    "                     max_bin=256)\n",
    "\n",
    "lgbm_distributions = {\n",
    "    \"num_leaves\": 2 ** np.array(range(1, 15)),\n",
    "    \"learning_rate\": 10 ** np.linspace(-2.5, -1),\n",
    "    \"colsample_bytree\": np.linspace(0.5, 1.0),\n",
    "    \"subsample\": np.linspace(0.5, 1.0),\n",
    "    \"reg_lambda\": 10 ** np.linspace(-2, 2)\n",
    "}\n",
    "\n",
    "search = HalvingRandomSearchCV(clf, lgbm_distributions, resource='n_estimators', **sh_params)\n",
    "                        \n",
    "t0 = time.time()\n",
    "with parallel_backend(\"loky\"): \n",
    "    search.fit(X_train, y_train.astype(np.int32), sample_weight=w_train)\n",
    "t_fit_lightgbm  = time.time()-t0\n",
    "\n",
    "print(\"Optimized LightGBM hyper-parameters:\")\n",
    "for k, v in search.best_params_.items():\n",
    "    print(\"%30s:\" % (k), v)\n",
    "\n",
    "score_lightgbm = weighted_log_loss(y_test, search.predict_proba(X_test)[:,1])\n",
    "\n",
    "res_lightgbm = pd.Series({'t_fit': t_fit_lightgbm, 'holdout_score': score_lightgbm}, name='lightgbm')\n",
    "df = df.append(res_lightgbm)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SnapBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpa/anaconda3/envs/snapenv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized SnapBoost hyper-parameters:\n",
      "       tree_select_probability: 0.9346938775510204\n",
      "                     subsample: 0.846938775510204\n",
      "                   regularizer: 6.250551925273976\n",
      "                  n_components: 58\n",
      "                     max_depth: 1\n",
      "                 learning_rate: 0.08094001216083124\n",
      "                     lambda_l2: 56.89866029018293\n",
      "                         gamma: 568.9866029018293\n",
      "                 fit_intercept: True\n",
      "              colsample_bytree: 0.5408163265306123\n",
      "                     num_round: 1024\n",
      "               t_fit  holdout_score\n",
      "xgboost   269.207851       0.266330\n",
      "lightgbm  213.848340       0.381463\n",
      "snapml    267.732386       0.253518\n"
     ]
    }
   ],
   "source": [
    "clf = SnapBoostingMachineClassifier(random_state=42, \n",
    "                                    n_jobs=1,\n",
    "                                    hist_nbins=256)\n",
    "\n",
    "snap_distributions = {\n",
    "    \"max_depth\": range(1, 20),\n",
    "    \"tree_select_probability\": np.linspace(0.9, 1.0),\n",
    "    \"learning_rate\": 10 ** np.linspace(-2.5, -1),\n",
    "    \"colsample_bytree\": np.linspace(0.5, 1.0),\n",
    "    \"subsample\": np.linspace(0.5, 1.0),\n",
    "    \"lambda_l2\": 10 ** np.linspace(-2, 2),\n",
    "    \"regularizer\": 10 ** np.linspace(-6, 3),\n",
    "    \"fit_intercept\": [False, True],\n",
    "    \"gamma\": 10 ** np.linspace(-3, 3),\n",
    "    \"n_components\": range(1, 100)   \n",
    "}\n",
    "\n",
    "search = HalvingRandomSearchCV(clf, snap_distributions, resource='num_round', **sh_params)\n",
    "                             \n",
    "t0 = time.time()\n",
    "with parallel_backend(\"loky\"): \n",
    "    search.fit(X_train, y_train, sample_weight=w_train)\n",
    "t_fit_snapml = time.time()-t0\n",
    "\n",
    "print(\"Optimized SnapBoost hyper-parameters:\")\n",
    "for k, v in search.best_params_.items():\n",
    "    print(\"%30s:\" % (k), v)\n",
    "    \n",
    "score_snapml = weighted_log_loss(y_test, search.predict_proba(X_test)[:,1])\n",
    "\n",
    "res_snapml = pd.Series({'t_fit': t_fit_snapml, 'holdout_score': score_snapml}, name='snapml')\n",
    "df = df.append(res_snapml)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_fit</th>\n",
       "      <th>holdout_score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>snapml</th>\n",
       "      <td>267.732386</td>\n",
       "      <td>0.253518</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>269.207851</td>\n",
       "      <td>0.266330</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>213.848340</td>\n",
       "      <td>0.381463</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               t_fit  holdout_score  rank\n",
       "snapml    267.732386       0.253518   1.0\n",
       "xgboost   269.207851       0.266330   2.0\n",
       "lightgbm  213.848340       0.381463   3.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='holdout_score')\n",
    "df['rank'] = df['holdout_score'].rank()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Performance results always depend on the hardware and software environment. \n",
    "\n",
    "Information regarding the environment that was used to run this notebook are provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            platform: macOS-10.16-x86_64-i386-64bit\n",
      "           cpu_count: 8\n",
      "        cpu_freq_min: 2300\n",
      "        cpu_freq_max: 2300\n",
      "        total_memory: 32.0\n",
      "      snapml_version: 1.7.0\n",
      "     sklearn_version: 0.24.1\n",
      "     xgboost_version: 1.3.3\n",
      "    lightgbm_version: 3.1.1\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "environment = utils.get_environment()\n",
    "for k,v in environment.items():\n",
    "    print(\"%20s: %s\" % (k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Statistics\n",
    "\n",
    "Finally, we record the enviroment and performance statistics for analysis outside of this standalone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "cpu_count": 8,
        "cpu_freq_max": 2300,
        "cpu_freq_min": 2300,
        "dataset": "CreditCardFraud",
        "lightgbm_version": "3.1.1",
        "model": "BoostingMachineClassifier",
        "n_classes": 2,
        "n_examples_test": 71202,
        "n_examples_train": 213605,
        "n_features": 28,
        "platform": "macOS-10.16-x86_64-i386-64bit",
        "score": "weighted_log_loss",
        "score_lightgbm": 0.3814626358232652,
        "score_snapml": 0.25351774172662755,
        "score_xgboost": 0.26632982394058535,
        "sklearn_version": "0.24.1",
        "snapml_version": "1.7.0",
        "t_fit_lightgbm": 213.84834003448486,
        "t_fit_snapml": 267.73238611221313,
        "t_fit_xgboost": 269.20785093307495,
        "total_memory": 32,
        "xgboost_version": "1.3.3"
       },
       "encoder": "json",
       "name": "result",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scrapbook as sb\n",
    "sb.glue(\"result\", {\n",
    "    'dataset': dataset.name,\n",
    "    'n_examples_train': X_train.shape[0],\n",
    "    'n_examples_test': X_test.shape[0],\n",
    "    'n_features': X_train.shape[1],\n",
    "    'n_classes': len(np.unique(y_train)),\n",
    "    'model': 'BoostingMachineClassifier',\n",
    "    'score': 'weighted_log_loss',\n",
    "    't_fit_xgboost': t_fit_xgboost,\n",
    "    'score_xgboost': score_xgboost,\n",
    "    't_fit_lightgbm': t_fit_lightgbm,\n",
    "    'score_lightgbm': score_lightgbm,\n",
    "    't_fit_snapml': t_fit_snapml,\n",
    "    'score_snapml': score_snapml,\n",
    "    **environment,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
