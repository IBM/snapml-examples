{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2021 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Allstate Dataset\n",
    "\n",
    "## Background \n",
    "\n",
    "The goal of this competition is to predict Bodily Injury Liability Insurance claim payments based on the characteristics of the insuredâ€™s vehicle. \n",
    "\n",
    "## Source\n",
    "\n",
    "The raw dataset can be obtained directly from the [Allstate Claim Prediction Challenge](https://www.kaggle.com/c/ClaimPredictionChallenge).\n",
    "\n",
    "In this example, we download the dataset directly from Kaggle using their API. In order for to work work, you must:\n",
    "1. Login into Kaggle and accept the [competition rules](https://www.kaggle.com/c/mercari-price-suggestion-challenge/rules).\n",
    "2. Folow [these instructions](https://www.kaggle.com/docs/api) to install your API token on your machine.\n",
    "\n",
    "## Goal\n",
    "The goal of this notebook is to illustrate how Snap ML can accelerate training of a logistic regression model on this dataset.\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tpa/Code/snapml-examples/examples\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR='cache-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datasets import Allstate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from snapml import LogisticRegression as SnapLogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating working directory: cache-dir/Allstate\n",
      "Downloading Allstate dataset.\n",
      "Preprocessing Allstate dataset.\n",
      "File Name                                             Modified             Size\n",
      "dictionary.html                                2019-12-11 04:17:20        24768\n",
      "example_compressed_entry.csv.gz                2019-12-11 04:17:20      9534348\n",
      "example_compressed_entry.zip                   2019-12-11 04:17:22      5120252\n",
      "example_uncompressed_entry.csv                 2019-12-11 04:17:22     51778401\n",
      "kaggle_srm6_stormod.sas7bitm                   2019-12-11 04:17:26       325632\n",
      "test_set.7z                                    2019-12-11 04:17:26     34841099\n",
      "test_set.zip                                   2019-12-11 04:17:30    116285954\n",
      "train_set.7z                                   2019-12-11 04:17:44    110548523\n",
      "train_set.zip                                  2019-12-11 04:17:56    380542114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tpa/anaconda3/envs/snapenv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3427: DtypeWarning: Columns (20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Row_ID  Household_ID  Vehicle  Calendar_Year  Model_Year  \\\n",
      "0                1             1        3           2005        2005   \n",
      "1                2             2        2           2005        2003   \n",
      "2                3             3        1           2005        1998   \n",
      "3                4             3        1           2006        1998   \n",
      "4                5             3        2           2005        2001   \n",
      "...            ...           ...      ...            ...         ...   \n",
      "13184285  13184286       7542110        1           2005        1987   \n",
      "13184286  13184287       7542111        1           2005        1989   \n",
      "13184287  13184288       7542112        1           2005        1990   \n",
      "13184288  13184289       7542112        2           2005        1998   \n",
      "13184289  13184290       7542113        1           2005        1996   \n",
      "\n",
      "         Blind_Make Blind_Model Blind_Submodel Cat1 Cat2  ...      Var5  \\\n",
      "0                 K        K.78         K.78.2    D    C  ...  1.008912   \n",
      "1                 Q        Q.22         Q.22.3    B    C  ...  1.240851   \n",
      "2                AR       AR.41        AR.41.1    B    ?  ... -0.971487   \n",
      "3                AR       AR.41        AR.41.1    B    ?  ... -0.971487   \n",
      "4                 D        D.20         D.20.0    J    C  ...  0.812656   \n",
      "...             ...         ...            ...  ...  ...  ...       ...   \n",
      "13184285         BW      BW.156       BW.156.0    I    ?  ...  1.663098   \n",
      "13184286         AJ      AJ.123       AJ.123.3    D    ?  ...  0.093052   \n",
      "13184287          X        X.52         X.52.1    B    ?  ... -0.840650   \n",
      "13184288          W         W.4          W.4.6    I    ?  ... -1.405628   \n",
      "13184289          M        M.13         M.13.2    F    ?  ... -1.066641   \n",
      "\n",
      "              Var6      Var7      Var8 NVCat   NVVar1    NVVar2    NVVar3  \\\n",
      "0         0.261040  0.907793 -0.077998     M -0.23153 -0.266117 -0.272337   \n",
      "1         0.432987 -0.726459  0.204785     O -0.23153 -0.266117 -0.272337   \n",
      "2        -1.405797 -0.837048 -1.176858     F -0.23153 -0.266117 -0.272337   \n",
      "3        -1.405797 -0.837048 -1.176858     F -0.23153 -0.266117 -0.272337   \n",
      "4         2.112691  1.534462  2.347260     F -0.23153 -0.266117 -0.272337   \n",
      "...            ...       ...       ...   ...      ...       ...       ...   \n",
      "13184285  0.841216  1.141258 -0.986731     M -0.23153 -0.266117 -0.272337   \n",
      "13184286 -0.203335  0.674329 -0.818812     M -0.23153 -0.266117 -0.272337   \n",
      "13184287 -1.169516 -1.205676 -1.451655     E -0.23153 -0.266117 -0.272337   \n",
      "13184288 -0.480556  0.145961 -0.191220     E -0.23153 -0.266117 -0.272337   \n",
      "13184289 -1.491186 -1.488291 -0.850317     O -0.23153 -0.266117 -0.272337   \n",
      "\n",
      "            NVVar4 Claim_Amount  \n",
      "0        -0.251419          0.0  \n",
      "1        -0.251419          0.0  \n",
      "2        -0.251419          0.0  \n",
      "3        -0.251419          0.0  \n",
      "4        -0.251419          0.0  \n",
      "...            ...          ...  \n",
      "13184285 -0.251419          0.0  \n",
      "13184286 -0.251419          0.0  \n",
      "13184287 -0.251419          0.0  \n",
      "13184288 -0.251419          0.0  \n",
      "13184289 -0.251419          0.0  \n",
      "\n",
      "[13184290 rows x 35 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ae0aca8a5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# note -- when the notebook is executed for the first time, the dataset will be downloaded and cached.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# subsequent runs of the notebook will simply read the cached datatset, and should be much faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCACHE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/snapml-examples/examples/datasets/dataset.py\u001b[0m in \u001b[0;36mget_train_test_split\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing %s dataset.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Writing binary %s dataset (cache) to disk.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# note -- when the notebook is executed for the first time, the dataset will be downloaded and cached.\n",
    "# subsequent runs of the notebook will simply read the cached datatset, and should be much faster.\n",
    "X_train, X_test, y_train, y_test = Allstate(cache_dir=CACHE_DIR).get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of examples: %d\" % (X_train.shape[0]))\n",
    "print(\"Number of features: %d\" % (X_train.shape[1]))\n",
    "print(\"Number of classes:  %d\" % (len(np.unique(y_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(fit_intercept=False, n_jobs=4)\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "t_fit_sklearn = time.time()-t0\n",
    "score_sklearn = roc_auc_score(y_test, lr.predict_proba(X_test)[:,1])\n",
    "print(\"Training time (sklearn): %6.2f seconds\" % (t_fit_sklearn))\n",
    "print(\"ROC AUC score (sklearn): %.4f\" % (score_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SnapLogisticRegression(fit_intercept=False, n_jobs=4)\n",
    "t0 = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "t_fit_snapml = time.time()-t0\n",
    "score_snapml = roc_auc_score(y_test, lr.predict_proba(X_test)[:,1])\n",
    "print(\"Training time (snapml): %6.2f seconds\" % (t_fit_snapml))\n",
    "print(\"ROC AUC score (snapml): %.4f\" % (score_snapml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up = t_fit_sklearn/t_fit_snapml\n",
    "score_diff = (score_snapml-score_sklearn)/score_sklearn\n",
    "print(\"Speed-up:                %.1f x\" % (speed_up))\n",
    "print(\"Relative diff. in score: %.4f\" % (score_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Performance results always depend on the hardware and software environment. \n",
    "\n",
    "This notebook was run on the following machine:\n",
    "* OS: MacOS 11.1 (Big Sur)\n",
    "* CPU: 2.3 GHz Quad-Core Intel Core i7\n",
    "* Memory: 32GB\n",
    "\n",
    "The versions of the relevant software packages are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snapml\n",
    "import sklearn\n",
    "print(\"scikit-learn version: %s\" % (sklearn.__version__))\n",
    "print(\"      snapml version: %s\" % (snapml.__version__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
