{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Machine on M5 Forecasting Accuracy Dataset\n",
    "\n",
    "## Background \n",
    "\n",
    "The goal of this learning task is to predict the daily sales in Walmart, the world's largest company by revenue, based on hierachical sales data from the past two years.\n",
    "\n",
    "## Source\n",
    "\n",
    "The raw dataset can be obtained directly from [Kaggle](https://www.kaggle.com/competitions/m5-forecasting-accuracy). \n",
    "\n",
    "In this example, we download the dataset directly from Kaggle using their API. \n",
    "\n",
    "In order for this to work, you must login into Kaggle and folow [these instructions](https://www.kaggle.com/docs/api) to install your API token on your machine.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to illustrate how Snap ML's boosting machine can perform Poisson regression and provide best-in-class accuracy when compared to XGBoost and LightGBM.\n",
    "\n",
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.637476Z",
     "iopub.status.busy": "2021-03-01T18:41:47.636547Z",
     "iopub.status.idle": "2021-03-01T18:41:47.638989Z",
     "shell.execute_reply": "2021-03-01T18:41:47.639682Z"
    }
   },
   "outputs": [],
   "source": [
    "CACHE_DIR='cache-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:47.644878Z",
     "iopub.status.busy": "2021-03-01T18:41:47.644123Z",
     "iopub.status.idle": "2021-03-01T18:41:50.150756Z",
     "shell.execute_reply": "2021-03-01T18:41:50.151221Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasets import M5Forecasting\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from snapml import BoostingMachineRegressor as SnapBoostingMachineRegressor\n",
    "from sklearn.metrics import mean_poisson_deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:50.155800Z",
     "iopub.status.busy": "2021-03-01T18:41:50.155146Z",
     "iopub.status.idle": "2021-03-01T18:41:50.499188Z",
     "shell.execute_reply": "2021-03-01T18:41:50.499565Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = M5Forecasting(cache_dir=CACHE_DIR)\n",
    "X_train, X_test, y_train, y_test = dataset.get_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-01T18:41:50.503412Z",
     "iopub.status.busy": "2021-03-01T18:41:50.502860Z",
     "iopub.status.idle": "2021-03-01T18:41:50.632471Z",
     "shell.execute_reply": "2021-03-01T18:41:50.632804Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of examples: %d\" % (X_train.shape[0]))\n",
    "print(\"Number of features: %d\" % (X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train all 3 boosting frameworks the Poisson objective. \n",
    "\n",
    "We will use the following parameters for the optimization in all cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUND = 100\n",
    "LEARNING_RATE = 0.5\n",
    "MAX_DEPTH = 6\n",
    "NUM_THREADS = 8\n",
    "LAMBDA_2 = 0.1\n",
    "MAX_DELTA_STEP = 0.7\n",
    "MAX_BINS = 256\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['poisson_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = dict(    \n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_estimators=NUM_ROUND,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    reg_lambda = LAMBDA_2,\n",
    "    max_delta_step = MAX_DELTA_STEP,\n",
    "    n_jobs = NUM_THREADS,    \n",
    "    min_child_weight = 0.0,  \n",
    "    max_bin = MAX_BINS,\n",
    "    random_state=RANDOM_STATE, \n",
    ")\n",
    "\n",
    "gbr_x = XGBRegressor(objective=\"count:poisson\",                    \n",
    "                   tree_method='hist',\n",
    "                   **params_xgb)\n",
    "                        \n",
    "gbr_x.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost Prediction   \n",
    "score_xgboost = mean_poisson_deviance(y_test, gbr_x.predict(X_test))\n",
    "    \n",
    "res_xgboost = pd.Series({'poisson_loss': score_xgboost}, name='xgboost')\n",
    "df = df.append(res_xgboost)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = dict(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    n_estimators=NUM_ROUND,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    reg_alpha = LAMBDA_2,\n",
    "    max_delta_step = MAX_DELTA_STEP,\n",
    "    n_jobs = NUM_THREADS, \n",
    "    min_child_weight = 0.0,\n",
    "    max_bin = MAX_BINS,\n",
    "    random_state=RANDOM_STATE,     \n",
    "    num_leaves = 2^MAX_DEPTH +1,\n",
    ")\n",
    "\n",
    "gbr_l = LGBMRegressor(objective='poisson',\n",
    "                      **params_lgb)\n",
    "                        \n",
    "gbr_l.fit(X_train, y_train)\n",
    "\n",
    "# LightGBM Prediction\n",
    "score_lightgbm = mean_poisson_deviance(y_test, gbr_l.predict(X_test))\n",
    "\n",
    "res_lightgbm = pd.Series({'poisson_loss': score_lightgbm}, name='lightgbm')\n",
    "df = df.append(res_lightgbm)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SnapBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_snap = dict(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_round=NUM_ROUND,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    lambda_l2 = LAMBDA_2,\n",
    "    max_delta_step = MAX_DELTA_STEP,\n",
    "    n_jobs = NUM_THREADS,\n",
    "    use_gpu =  False,\n",
    "    use_histograms = True,\n",
    "    hist_nbins = MAX_BINS\n",
    ")\n",
    "\n",
    "\n",
    "gbr_s = SnapBoostingMachineRegressor(objective = \"poisson\",\n",
    "                                    random_state=42, \n",
    "                                    **params_snap)\n",
    "                             \n",
    "gbr_s.fit(X_train, y_train)\n",
    "\n",
    "# SnapBoost Prediction    \n",
    "score_snapml = mean_poisson_deviance(y_test, gbr_s.predict(X_test))\n",
    "\n",
    "res_snapml = pd.Series({'poisson_loss': score_snapml}, name='snapml')\n",
    "df = df.append(res_snapml)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='poisson_loss')\n",
    "df['rank'] = df['poisson_loss'].rank()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Performance results always depend on the hardware and software environment. \n",
    "\n",
    "Information regarding the environment that was used to run this notebook are provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "environment = utils.get_environment()\n",
    "for k,v in environment.items():\n",
    "    print(\"%20s: %s\" % (k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Statistics\n",
    "\n",
    "Finally, we record the enviroment and performance statistics for analysis outside of this standalone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapbook as sb\n",
    "sb.glue(\"result\", {\n",
    "    'dataset': dataset.name,\n",
    "    'n_examples_train': X_train.shape[0],\n",
    "    'n_examples_test': X_test.shape[0],\n",
    "    'n_features': X_train.shape[1],\n",
    "    'model': 'BoostingMachineRegressor',\n",
    "    'score': 'mean_poisson_deviance',    \n",
    "    'score_xgboost': score_xgboost,\n",
    "    'score_lightgbm': score_lightgbm,\n",
    "    'score_snapml': score_snapml,\n",
    "    **environment,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
