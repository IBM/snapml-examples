{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2022 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Features Extraction for Anti-Money Laudering\n",
    "\n",
    "The Snap ML GraphFeaturePreprocessor is a scikit-learn compatible preprocessor that enables scalable and real-time feature extraction from graph-structured data. It provides utilities for creating and updating in-memory graphs as well as extracting new features from these graphs. The goal of this example is to show how to use the API of this preprocessor. As input, we will use a synthethic dataset in tabular format where each row represents a financial transaction. For each transaction 4 features are available: transaction ID, source account ID, target accound ID and transaction timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Graph Feature Preprocessor from Snap ML\n",
    "from snapml import GraphFeaturePreprocessor\n",
    "\n",
    "# Import other libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume that the user has access to a set of (labeled) transactions with raw features which could be used to train a machine learning (ML) model, e.g., for fraud detection. The user will extract graph features using the Graph Features Preprocessor which will be added to the initial raw features present in the transactions. The enriched set of features will be used to train an ML model. The main steps associated with this use case are shown below:\n",
    "\n",
    "<div> <img src=\"img/gfp-use-case1.png\" width=\"1000\"> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file that contains financial transactions, e.g., used for training ML models\n",
    "train_graph_path = \"../datasets/graph_feature_preprocessor/aml_custom_train.txt\"\n",
    "\n",
    "print(\"Loading the transactions \")\n",
    "X_train = np.loadtxt(train_graph_path, dtype=np.float64, delimiter=\" \", comments=\"#\", usecols=range(4))\n",
    "print(\"Input dataset shape: \", X_train.shape)\n",
    "\n",
    "df = pd.DataFrame(X_train, columns=['transactionID', 'sourceAccountID', 'targetAccountID', 'timestamp'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following dictionary defines the configuration parameters of the Graph Feature Preprocessor\n",
    "\n",
    "params = {\n",
    "    \"num_threads\": 4,             # number of software threads to be used (important for performance)\n",
    "    \"time_window\": 16,            # time window used if no pattern was specified\n",
    "    \n",
    "    \"vertex_stats\": True,         # produce vertex statistics\n",
    "    \"vertex_stats_cols\": [3],     # produce vertex statistics using the selected input columns\n",
    "    \n",
    "    # features: 0:fan,1:deg,2:ratio,3:avg,4:sum,5:min,6:max,7:median,8:var,9:skew,10:kurtosis\n",
    "    \"vertex_stats_feats\": [0, 1, 2, 3, 4, 8, 9, 10],  # fan,deg,ratio,avg,sum,var,skew,kurtosis\n",
    "    \n",
    "    # fan in/out parameters\n",
    "    \"fan\": True,\n",
    "    \"fan_tw\": 16,\n",
    "    \"fan_bins\": [y+2 for y in range(2)],\n",
    "    \n",
    "    # in/out degree parameters\n",
    "    \"degree\": True,\n",
    "    \"degree_tw\": 16,\n",
    "    \"degree_bins\": [y+2 for y in range(2)],\n",
    "    \n",
    "    # scatter gather parameters\n",
    "    \"scatter-gather\": True,\n",
    "    \"scatter-gather_tw\": 16,\n",
    "    \"scatter-gather_bins\": [y+2 for y in range(2)],\n",
    "    \n",
    "    # temporal cycle parameters\n",
    "    \"temp-cycle\": True,\n",
    "    \"temp-cycle_tw\": 16,\n",
    "    \"temp-cycle_bins\": [y+2 for y in range(2)],\n",
    "    \n",
    "    # length-constrained simple cycle parameters\n",
    "    \"lc-cycle\": False,\n",
    "    \"lc-cycle_tw\": 16,\n",
    "    \"lc-cycle_len\": 8,\n",
    "    \"lc-cycle_bins\": [y+2 for y in range(2)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Graph Feature Preprocessor, set its configuration using the above dictionary and verify it\n",
    "\n",
    "print(\"Creating a graph feature preprocessor \")\n",
    "gp = GraphFeaturePreprocessor()\n",
    "\n",
    "print(\"Setting the parameters of the graph feature preprocessor \")\n",
    "gp.set_params(params)\n",
    "\n",
    "print(\"Graph feature preprocessor parameters: \", json.dumps(gp.get_params(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enriching the transactions with new graph features \")\n",
    "print(\"Raw dataset shape: \", X_train.shape)\n",
    "\n",
    "# the fit_transform and transform functions are equivalent\n",
    "# these functions can run on single transactions or on batches of transactions\n",
    "X_train_enriched = gp.fit_transform(X_train.astype(\"float64\")) \n",
    "\n",
    "print(\"Enriched dataset shape: \", X_train_enriched.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper function to inspect the newly generated graph-based features for a given transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_enriched_transaction(transaction, params):\n",
    "    colnames = []\n",
    "    \n",
    "    # add raw features names\n",
    "    colnames.append(\"transactionID\")\n",
    "    colnames.append(\"sourceAccountID\")\n",
    "    colnames.append(\"targetAccountID\")\n",
    "    colnames.append(\"timestamp\")\n",
    "    \n",
    "    # add features names for the graph patterns\n",
    "    for pattern in ['fan', 'degree', 'scatter-gather', 'temp-cycle', 'lc-cycle']:\n",
    "        if pattern in params:\n",
    "            if params[pattern]:\n",
    "                bins = len(params[pattern +'_bins'])\n",
    "                if pattern in ['fan', 'degree']:\n",
    "                    for i in range(bins-1):\n",
    "                        colnames.append(pattern+\"_in_bins_\"+str(params[pattern +'_bins'][i])+\"-\"+str(params[pattern +'_bins'][i+1]))\n",
    "                    colnames.append(pattern+\"_in_bins_\"+str(params[pattern +'_bins'][i+1])+\"-inf\")\n",
    "                    for i in range(bins-1):\n",
    "                        colnames.append(pattern+\"_out_bins_\"+str(params[pattern +'_bins'][i])+\"-\"+str(params[pattern +'_bins'][i+1]))\n",
    "                    colnames.append(pattern+\"_out_bins_\"+str(params[pattern +'_bins'][i+1])+\"-inf\")\n",
    "                else:\n",
    "                    for i in range(bins-1):\n",
    "                        colnames.append(pattern+\"_bins_\"+str(params[pattern +'_bins'][i])+\"-\"+str(params[pattern +'_bins'][i+1]))\n",
    "                    colnames.append(pattern+\"_bins_\"+str(params[pattern +'_bins'][i+1])+\"-inf\")\n",
    "\n",
    "    vert_feat_names = [\"fan\",\"deg\",\"ratio\",\"avg\",\"sum\",\"min\",\"max\",\"median\",\"var\",\"skew\",\"kurtosis\"]\n",
    "\n",
    "    # add features names for the vertex statistics\n",
    "    for orig in ['source', 'dest']:\n",
    "        for direction in ['out', 'in']:\n",
    "            # add fan, deg, and ratio features\n",
    "            for k in [0, 1, 2]:\n",
    "                if k in params[\"vertex_stats_feats\"]:\n",
    "                    feat_name = orig + \"_\" + vert_feat_names[k] + \"_\" + direction\n",
    "                    colnames.append(feat_name)\n",
    "            for col in params[\"vertex_stats_cols\"]:\n",
    "                # add avg, sum, min, max, median, var, skew, and kurtosis features\n",
    "                for k in [3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "                    if k in params[\"vertex_stats_feats\"]:\n",
    "                        feat_name = orig + \"_\" + vert_feat_names[k] + \"_col\" + str(col) + \"_\" + direction\n",
    "                        colnames.append(feat_name)\n",
    "\n",
    "    df = pd.DataFrame(transaction, columns=colnames)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enriched transactions: \")\n",
    "print_enriched_transaction(X_train_enriched, gp.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This newly enriched set of transactions can now be used to train a ML model. Once trained, the model can be used for prediction (e.g., detect anomalies) on new (unlabeled) transactions. The main steps associated with this use case is shown below:\n",
    "\n",
    "<div> <img src=\"img/gfp-use-case2.png\" width=\"1000\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file that contains financial transactions used for testing\n",
    "test_transactions_path = \"../datasets/graph_feature_preprocessor/aml_custom_test.txt\"\n",
    "\n",
    "print(\"Loading the test transactions \")\n",
    "X_test = np.loadtxt(test_transactions_path, dtype=np.float64, delimiter=\" \", comments=\"#\", usecols=range(4))\n",
    "print(\"Input dataset shape: \", X_test.shape)\n",
    "\n",
    "df = pd.DataFrame(X_test, columns=['transactionID', 'sourceAccountID', 'destinationAccountID', 'timestamp'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating a graph feature preprocessor \")\n",
    "gp = GraphFeaturePreprocessor()\n",
    "\n",
    "print(\"Setting the parameters of the graph feature preprocessor \")\n",
    "gp.set_params(params)\n",
    "\n",
    "print(\"Creating the graph using the training transactions \")\n",
    "gp.fit(X_train)  # this step is optional, however recommended for capturing deeper graph feature\n",
    "\n",
    "# transform can run on single transactions or on batches of transactions\n",
    "print(\"Enriching the test transactions with new graph features \")\n",
    "X_test_enriched = gp.transform(X_test.astype(\"float64\"))\n",
    "print_enriched_transaction(X_test_enriched, gp.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the enriched transactions can be used as input to the ML model previously trained. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
